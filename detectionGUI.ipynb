{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements for this program to run.\n",
    "* Install the following via Anaconda Prompt\n",
    "    - pyqt5 (pip install pyqt5)\n",
    "    - pyqt5-tools (pip install pyqt5-tools)\n",
    "    - tensorflow\n",
    "    - imageai\n",
    "* Trianed Model and .json file (Both must be located as the same path of this file)\n",
    "* Qt Designer\n",
    "* Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Install the following via Anaconda Prompt\n",
    "#-------------------------------------------------\n",
    "# pip install opencv-python==4.1.2.30\n",
    "# pip uninstall keras-nightly -y\n",
    "# pip install keras==2.3.1\n",
    "# pip install tensorflow==1.14.0\n",
    "# pip install 'h5py==2.10.0' --force-reinstall\n",
    "# pip install imageai==2.1.5\n",
    "# pip install pyqt5\n",
    "# conda install -c anaconda pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alzheimer's Disease Stage Classification System Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RYZEN\\.conda\\envs\\myenv2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "#-------------------------------------------------\n",
    "from PyQt5 import QtWidgets, QtGui, QtCore\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QDesktopWidget, QFileDialog, QMessageBox\n",
    "from imageai.Detection.Custom import CustomObjectDetection\n",
    "from imageai.Detection.Custom import CustomVideoObjectDetection\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import csv \n",
    "import time\n",
    "import csv\n",
    "import argparse \n",
    "import datetime \n",
    "import pandas as pd\n",
    "#-------------------------------------------------\n",
    "\n",
    "#Application's Details\n",
    "#-------------------------------------------------\n",
    "class MyWindow(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super(MyWindow, self).__init__()\n",
    "        #Set Fixed Resolution Size to 600\n",
    "        self.setFixedSize(800, 600)\n",
    "        self.setWindowTitle(\"ALZHEIMER'S DISEASE STAGE CLASSIFICATION GUI\")\n",
    "        #Background Color\n",
    "        self.setStyleSheet(\"background-color: rgb(rgb(200, 198, 200))\")\n",
    "        self.initUI()\n",
    "        self.center()\n",
    "#-------------------------------------------------\n",
    "        \n",
    "#Set Form to Center Screen\n",
    "#-------------------------------------------------\n",
    "    def center(self):\n",
    "        qr = self.frameGeometry()\n",
    "        cp = QDesktopWidget().availableGeometry().center()\n",
    "        qr.moveCenter(cp)\n",
    "        self.move(qr.topLeft())\n",
    "#-------------------------------------------------\n",
    "    \n",
    "#Code for widgets (Labels and Buttons)\n",
    "#-------------------------------------------------\n",
    "    def initUI(self):\n",
    "            #Icon\n",
    "            icon = QtGui.QIcon()\n",
    "            icon.addPixmap(QtGui.QPixmap(\"art/object_detection_logo2.png\"), QtGui.QIcon.Normal, QtGui.QIcon.Off)\n",
    "            self.setWindowIcon(icon)\n",
    "            self.setWindowOpacity(30.0)\n",
    "            self.setToolButtonStyle(QtCore.Qt.ToolButtonTextBesideIcon)\n",
    "            self.setDocumentMode(False)\n",
    "            \n",
    "            #Title Label\n",
    "            self.title = QtWidgets.QLabel(self)\n",
    "            self.title.setText(\"ALZHEIMER'S DISEASE STAGE CLASSIFICATION USING DEEP LEARNING\")    \n",
    "            self.title.setFont(QtGui.QFont('Berlin Sans FB', 12))\n",
    "            self.title.setStyleSheet(\"font-weight: bold\");\n",
    "            self.title.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.title.setGeometry(QtCore.QRect(0, 40, 801, 61))\n",
    "\n",
    "            #Label 2\n",
    "            self.label2 = QtWidgets.QLabel(self)\n",
    "            self.label2.setText(\"Detects 3 Stages of Alzheimer's Disease\")    \n",
    "            self.label2.setFont(QtGui.QFont('Berlin Sans FB', 12))\n",
    "            self.label2.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.label2.setGeometry(QtCore.QRect(0, 90, 791, 31))\n",
    "            \n",
    "            #Label 3\n",
    "            self.label3 = QtWidgets.QLabel(self)\n",
    "            self.label3.setText(\"Non Demented • Mild Demented • Very Mild Demented\")    \n",
    "            self.label3.setFont(QtGui.QFont('Berlin Sans FB', 12))\n",
    "            self.label3.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.label3.setGeometry(QtCore.QRect(0, 120, 791, 31))\n",
    "                 \n",
    "            #object detection Icon\n",
    "            self.iconlabel = QtWidgets.QLabel(self)\n",
    "            self.iconlabel.setText(\"\")\n",
    "            self.iconlabel.setPixmap(QtGui.QPixmap(\"art/brain.png\"))\n",
    "            self.iconlabel.setScaledContents(True)\n",
    "            self.iconlabel.setGeometry(QtCore.QRect(700, 20, 80, 80))\n",
    "            \n",
    "            #yolov3 Label\n",
    "            self.dept = QtWidgets.QLabel(self)\n",
    "            self.dept.setText(\"TRAINED USING YOLO V3 ALGORITHM\")    \n",
    "            self.dept.setFont(QtGui.QFont('Berlin Sans FB', 9))\n",
    "            self.dept.setScaledContents(True)\n",
    "            self.dept.setWordWrap(False)\n",
    "            self.dept.setGeometry(QtCore.QRect(300, 560, 801, 31))\n",
    "            \n",
    "            #Image Label\n",
    "            self.Imglabel = QtWidgets.QLabel(self)\n",
    "            self.Imglabel.setText(\"IMAGE\")    \n",
    "            self.Imglabel.setFont(QtGui.QFont('Berlin Sans FB', 16))\n",
    "            self.Imglabel.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.Imglabel.setGeometry(QtCore.QRect(90, 190, 111, 41))\n",
    "\n",
    "            \n",
    "            #Image Button\n",
    "            self.ImgBtn = QtWidgets.QPushButton(self)\n",
    "            self.ImgBtn.setGeometry(QtCore.QRect(60, 230, 165, 165))\n",
    "            self.ImgBtn.setText(\"\")\n",
    "            self.ImgBtn.setToolTip('Import image')\n",
    "            \n",
    "            \n",
    "            #Image Icon\n",
    "            imgbtnicon = QtGui.QIcon()\n",
    "            imgbtnicon.addPixmap(QtGui.QPixmap(\"art/image_icon.ico\"), QtGui.QIcon.Normal, QtGui.QIcon.Off)\n",
    "            self.ImgBtn.setIcon(imgbtnicon)\n",
    "            self.ImgBtn.setIconSize(QtCore.QSize(160, 160))\n",
    "            self.ImgBtn.setFlat(True)\n",
    "            \n",
    "            #Image Button Click Event\n",
    "            self.ImgBtn.clicked.connect(self.getImage)\n",
    "            \n",
    "            #Video Label\n",
    "            self.Vidlabel = QtWidgets.QLabel(self)\n",
    "            self.Vidlabel.setText(\"VIDEO\")\n",
    "            self.Vidlabel.setFont(QtGui.QFont('Berlin Sans FB', 16))\n",
    "            self.Vidlabel.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.Vidlabel.setGeometry(QtCore.QRect(590, 180, 101, 51))\n",
    "            \n",
    "            #Video Button\n",
    "            self.VidBtn = QtWidgets.QPushButton(self)\n",
    "            self.VidBtn.setGeometry(QtCore.QRect(560, 230, 165, 165))\n",
    "            self.VidBtn.setText(\"\")\n",
    "            self.VidBtn.setToolTip('Import video') \n",
    "            \n",
    "            #Video Icon\n",
    "            vidbtnicon = QtGui.QIcon()\n",
    "            vidbtnicon.addPixmap(QtGui.QPixmap(\"art/video_icon.ico\"), QtGui.QIcon.Normal, QtGui.QIcon.Off)\n",
    "            self.VidBtn.setIcon(vidbtnicon)\n",
    "            self.VidBtn.setIconSize(QtCore.QSize(160, 160))\n",
    "            self.VidBtn.setFlat(True)                        \n",
    "            \n",
    "            #Button Click Event\n",
    "            self.VidBtn.clicked.connect(self.getVideo)\n",
    "           \n",
    "            #Live Label\n",
    "            self.livelabel = QtWidgets.QLabel(self)\n",
    "            self.livelabel.setText(\"WEBCAM\")\n",
    "            self.livelabel.setFont(QtGui.QFont('Berlin Sans FB', 16))\n",
    "            self.livelabel.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.livelabel.setGeometry(QtCore.QRect(315, 180, 171, 51))\n",
    "            \n",
    "            #Live Button\n",
    "            self.livebtn = QtWidgets.QPushButton(self)\n",
    "            self.livebtn.setGeometry(QtCore.QRect(320, 230, 165, 165))\n",
    "            self.livebtn.setText(\"\")\n",
    "            self.livebtn.setToolTip('Use webcam')\n",
    "            \n",
    "            #Live Icon\n",
    "            livebtnicon = QtGui.QIcon()\n",
    "            livebtnicon.addPixmap(QtGui.QPixmap(\"art/webcam_icon.ico\"), QtGui.QIcon.Normal, QtGui.QIcon.Off)\n",
    "            self.livebtn.setIcon(livebtnicon)\n",
    "            self.livebtn.setIconSize(QtCore.QSize(160, 160))\n",
    "            self.livebtn.setFlat(True) \n",
    "            \n",
    "            #Button Click Event\n",
    "            self.livebtn.clicked.connect(self.Livestream)\n",
    "            \n",
    "#-------------------------------------------------\n",
    "\n",
    "#Select Image from your Computer to Detect\n",
    "#-------------------------------------------------\n",
    "    def getImage(self):\n",
    "        fname = QFileDialog.getOpenFileName(self, 'Open file', 'c:/',\"Image files (*.jpg *.png)\")\n",
    "        #Setting Variable name \"imagePath\" to global so it can be called at def DetectImage()\n",
    "        global imagePath\n",
    "        imagePath = fname[0]\n",
    "        self.DetectImage()\n",
    "        \n",
    "#Code For Single Image Detection\n",
    "#-------------------------------------------------\n",
    "    def DetectImage(self):\n",
    "        from datetime import datetime\n",
    "        today = datetime.now()\n",
    "        \n",
    "       \n",
    "        #Main Code for Hololens\n",
    "        detector = CustomObjectDetection()\n",
    "        detector.setModelTypeAsYOLOv3()\n",
    "        #Model Used\n",
    "        detector.setModelPath(\"detection_model-ex-024--loss-0000.169.h5\")\n",
    "        detector.setJsonPath(\"detection_config.json\")\n",
    "        detector.loadModel()\n",
    "        detections = detector.detectObjectsFromImage(input_image=imagePath, \n",
    "                                                     output_image_path= imagePath + \"_detected_alzheimer_stage.jpg\", \n",
    "                                                     minimum_percentage_probability=30)\n",
    "\n",
    "        #Create CSV File from the image\n",
    "        with open('single-image.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            #columns name\n",
    "            writer.writerow(['CLASS', 'PERCENTAGE'])\n",
    "            for (eachObject) in detections:\n",
    "                writer.writerow([eachObject[\"name\"], eachObject[\"percentage_probability\"]])\n",
    "\n",
    "        self.popupImage()\n",
    "        \n",
    "#Show popup message after finishing the Image Detection\n",
    "#-------------------------------------------------\n",
    "    def popupImage(self):\n",
    "        msg = QMessageBox()\n",
    "        msg.setWindowTitle(\"Single-Image Detection\")\n",
    "        msg.setText(\"Single Detection Finish\")\n",
    "        msg.setIcon(QMessageBox.Information)\n",
    "        x = msg.exec_()\n",
    "\n",
    "\n",
    "#Select Video from your Computer to Detect\n",
    "#-------------------------------------------------\n",
    "    def getVideo(self):\n",
    "        vidname = QFileDialog.getOpenFileName(self, 'Open file', 'c:/',\"Video files (*.avi *.mp4)\")\n",
    "        #Setting Variable name \"aviPath\" to global so it can be called at def DetectVideo()\n",
    "        global aviPath\n",
    "        aviPath = vidname[0]\n",
    "        #call def DectectVideo\n",
    "        self.DetectVideo()\n",
    "        \n",
    "#Code for Video Detection\n",
    "#-------------------------------------------------\n",
    "    def DetectVideo(self):\n",
    "        from datetime import datetime\n",
    "        classid = []\n",
    "        percentage =[]\n",
    "        execution_path = os.getcwd()\n",
    "\n",
    "    # FOR DETECTION\n",
    "        def forFrame(frame_number, output_array, output_count):\n",
    "            for eachObject in output_array:\n",
    "                classid.append(eachObject[\"name\"])\n",
    "                percentage.append(eachObject[\"percentage_probability\"])\n",
    "                \n",
    "        rec_detector = CustomVideoObjectDetection()\n",
    "        rec_detector.setModelTypeAsYOLOv3()\n",
    "        rec_detector.setModelPath(\"detection_model-ex-024--loss-0000.169.h5\")\n",
    "        rec_detector.setJsonPath(\"detection_config.json\")\n",
    "        rec_detector.loadModel()\n",
    "        rec_detector.detectObjectsFromVideo(input_file_path=aviPath,\n",
    "                                                  output_file_path=os.path.join(execution_path, aviPath + \"detected_hololens\"),\n",
    "                                                  per_frame_function=forFrame,\n",
    "                                                  minimum_percentage_probability=30,\n",
    "                                                  log_progress=True)\n",
    "        \n",
    "        \n",
    "        #Create CSV File from the image\n",
    "        with open('video-image.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            #columns name\n",
    "            writer.writerow(['CLASS', 'PERCENTAGE'])\n",
    "            for (classid_x, percentage_x) in zip (classid, percentage):\n",
    "                writer.writerow([classid_x, percentage_x])\n",
    "        self.popupVid()\n",
    "        \n",
    "        \n",
    "#Show popup message after finishing the Video Detection\n",
    "#-------------------------------------------------\n",
    "    def popupVid(self):\n",
    "        msg2 = QMessageBox()\n",
    "        msg2.setWindowTitle(\"Video Detection\")\n",
    "        msg2.setText(\"Video Dectection Finish\")\n",
    "        msg2.setIcon(QMessageBox.Information)\n",
    "        y = msg2.exec_()        \n",
    "            \n",
    "\n",
    "#Code for Live Detection\n",
    "#-------------------------------------------------\n",
    "    def Livestream(self):\n",
    "        from datetime import datetime\n",
    "        classid = []\n",
    "        percentage =[]\n",
    "        execution_path = os.getcwd() \n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # FOR DETECTION\n",
    "        #Get Values\n",
    "        def forFrameLive(frame_number, output_array, output_count):\n",
    "            for eachObject in output_array:\n",
    "                classid.append(eachObject[\"name\"])\n",
    "                percentage.append(eachObject[\"percentage_probability\"])\n",
    "                \n",
    "        video_detector = CustomVideoObjectDetection()\n",
    "        video_detector.setModelTypeAsYOLOv3()\n",
    "        #Model Used\n",
    "        video_detector.setModelPath(\"detection_model-ex-024--loss-0000.169.h5\")\n",
    "        video_detector.setJsonPath(\"detection_config.json\")\n",
    "        video_detector.loadModel()\n",
    "        video_detector.detectObjectsFromVideo(camera_input=cap, \n",
    "                                                            output_file_path=os.path.join(execution_path, \"LiveFeedOutput\"),\n",
    "                                                            per_frame_function=forFrameLive,  minimum_percentage_probability=50,\n",
    "                                                            detection_timeout=6)\n",
    "\n",
    "        \n",
    "        #Create CSV File from the video\n",
    "        with open('live_data.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            #columns name\n",
    "            writer.writerow(['CLASS', 'PERCENTAGE'])\n",
    "            for (classid_x, percentage_x) in zip (classid, percentage):\n",
    "                writer.writerow([classid_x, percentage_x])\n",
    "        self.popupLive()\n",
    "        \n",
    "#Show popup Window after Finishing the Live Detection\n",
    "#-------------------------------------------------\n",
    "    def popupLive(self):\n",
    "        msg3 = QMessageBox()\n",
    "        msg3.setWindowTitle(\"Live Detection\")\n",
    "        msg3.setText(\"Live Dectection Finish\")\n",
    "        msg3.setIcon(QMessageBox.Information)\n",
    "        z = msg3.exec_()\n",
    "        \n",
    "#Open GUI\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    win = MyWindow()\n",
    "    win.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select webcam  from your Computer to Detect\n",
    "#-------------------------------------------------\n",
    "#    def getLive(self):\n",
    "#        camera = QFileDialog.getOpenFileName(self, 'Open file', 'c:/',\"Video files (*.avi *.mp4)\")\n",
    "#        #Setting Variable name \"livePath\" to global so it can be called at def Livestream()\n",
    "#        global livePath\n",
    "#        livePath = camera[0]\n",
    "#        #call def Livestream\n",
    "#        self.Livestream()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
